{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e3a2436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x210c18db1f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "\n",
    "torch.manual_seed(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f20f27",
   "metadata": {},
   "source": [
    "### Craeting Dataset :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece18d5f",
   "metadata": {},
   "source": [
    "Creating two tensors, x and y, each containing 10 evenly spaced values within specified ranges and  linear sequences from 1 to 10 for x, and from 10 to 1 for y, representing data points then concatenates tensors x and y by reshaping them into column vectors and stacking them side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd3e1663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 10.],\n",
       "        [ 2.,  9.],\n",
       "        [ 3.,  8.],\n",
       "        [ 4.,  7.],\n",
       "        [ 5.,  6.],\n",
       "        [ 6.,  5.],\n",
       "        [ 7.,  4.],\n",
       "        [ 8.,  3.],\n",
       "        [ 9.,  2.],\n",
       "        [10.,  1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.linspace(1, 10, 10)\n",
    "y = torch.linspace(10, 1, 10)\n",
    "\n",
    "torch.cat((x.view(len(x),-1),y.view(len(y),-1)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d31165",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Data.TensorDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d7ac69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x210c759cb20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e20008e",
   "metadata": {},
   "source": [
    "### Training :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0985b81",
   "metadata": {},
   "source": [
    "Training a model using a DataLoader for efficient data handling which iterates through three epochs, processing data in batches of five. Each epoch's progress and batch data are printed, aiding in training monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82f711c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "loader = Data.DataLoader(dataset = dataset, \n",
    "                         batch_size = batch_size, \n",
    "                         shuffle = True, \n",
    "                         num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4caf5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0  | Step : 0  | batch_x : [ 6.  1. 10.  4.  2.]  | batch_y : [ 5. 10.  1.  7.  9.]\n",
      "Epoch : 0  | Step : 1  | batch_x : [7. 3. 5. 8. 9.]  | batch_y : [4. 8. 6. 3. 2.]\n",
      "Epoch : 1  | Step : 0  | batch_x : [8. 6. 1. 3. 4.]  | batch_y : [ 3.  5. 10.  8.  7.]\n",
      "Epoch : 1  | Step : 1  | batch_x : [ 9. 10.  7.  2.  5.]  | batch_y : [2. 1. 4. 9. 6.]\n",
      "Epoch : 2  | Step : 0  | batch_x : [7. 1. 8. 5. 2.]  | batch_y : [ 4. 10.  3.  6.  9.]\n",
      "Epoch : 2  | Step : 1  | batch_x : [ 3.  9. 10.  6.  4.]  | batch_y : [8. 2. 1. 5. 7.]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (3):\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        print('Epoch :', epoch, ' | Step :', step, ' | batch_x :', batch_x.numpy(), ' | batch_y :', batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048792bf",
   "metadata": {},
   "source": [
    "Training a model using a DataLoader for efficient data handling which iterates through three epochs, processing data in batches of ten. Each epoch's progress and batch data are printed, aiding in training monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01670080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 | steps : 1 |batch_x : [ 2.  6.  1.  7.  4.  9. 10.  5.  8.  3.] |batch_y : [ 9.  5. 10.  4.  7.  2.  1.  6.  3.  8.]\n",
      "Epoch : 1 | steps : 1 |batch_x : [ 9.  2.  7.  8.  3.  5.  6.  4.  1. 10.] |batch_y : [ 2.  9.  4.  3.  8.  6.  5.  7. 10.  1.]\n",
      "Epoch : 2 | steps : 1 |batch_x : [ 8.  2.  6.  3.  9.  4.  1.  7. 10.  5.] |batch_y : [ 3.  9.  5.  8.  2.  7. 10.  4.  1.  6.]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "loader = Data.DataLoader(dataset = dataset, \n",
    "                         batch_size = batch_size, \n",
    "                         shuffle = True, \n",
    "                         num_workers = 1)\n",
    "\n",
    "for epoch in range (3):\n",
    "    for steps, (batch_x, batch_y) in enumerate (loader):\n",
    "        print('Epoch :', epoch, '| steps :', step, '|batch_x :', batch_x.numpy(), '|batch_y :', batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "086f4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa8e2852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:19<00:00, 513810.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 2944617.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:07<00:00, 211221.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dsets.MNIST(root = './data', \n",
    "                            train = True, \n",
    "                            transform = transforms.ToTensor(), \n",
    "                            download = True)\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "print(image.size())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b2f6e4",
   "metadata": {},
   "source": [
    "### Batch Training with Image Dataset ( MNIST ) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ab7be",
   "metadata": {},
   "source": [
    "### Loading Dataset :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a43cf9",
   "metadata": {},
   "source": [
    "DataLoader named train_dataloader to manage a training dataset. It configures the DataLoader to process batches of 100 samples each, shuffle the data before batching, and utilize 2 worker processes for parallel data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5e920c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset = train_dataset, \n",
    "                                               batch_size = 100, \n",
    "                                               shuffle = True, \n",
    "                                               num_workers = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d713753",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_dataloader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1029e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_dataloader)\n",
    "batch = next(data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00be3f39",
   "metadata": {},
   "source": [
    "The ResNet-18 model is loaded with pre-trained weights which modifies the fully connected (fc) layer to accommodate a new output size of 100. Random input images (10 samples) are created, passed through the modified ResNet, and the resulting output size is printed the setting up the gradient computation of the pre-trained layers to false to retain the pre-trained knowledge during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21a167cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "E:\\Anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\DELL/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:22<00:00, 2.10MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained = True)                    #pretrained model\n",
    "\n",
    "for params in resnet.parameters():\n",
    "    params.requires_grad = False\n",
    "    \n",
    "resnet.fc = torch.nn.Linear(resnet.fc.in_features, 100)\n",
    "\n",
    "images = torch.autograd.Variable(torch.randn(10, 3, 256, 256))\n",
    "outputs = resnet(images)\n",
    "print (outputs.size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7396c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
